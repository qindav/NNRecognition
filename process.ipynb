{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "process.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JP83zPNchsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "43468b85-4e80-4124-c0f9-dc45e2da4768"
      },
      "source": [
        "# Lots of headers, though some may be unused rn\n",
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "\n",
        "from moviepy.editor import VideoFileClip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1458176/45929032 bytes (3.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5259264/45929032 bytes (11.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9101312/45929032 bytes (19.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12943360/45929032 bytes (28.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16801792/45929032 bytes (36.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20553728/45929032 bytes (44.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23830528/45929032 bytes (51.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27607040/45929032 bytes (60.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31440896/45929032 bytes (68.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35241984/45929032 bytes (76.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39157760/45929032 bytes (85.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42926080/45929032 bytes (93.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXFpYE-NnUoz",
        "colab_type": "text"
      },
      "source": [
        "Part 1: Partition the video into frames and save within a temp folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-bhrKFzbc5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a7ef09ca-5545-4426-c142-af346ba82fe3"
      },
      "source": [
        "# Uses google colab for this, you may have to use your own.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqLGDOgencs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c863ea0c-254f-40ca-e17e-aa63b1499128"
      },
      "source": [
        "cd drive/'My Drive'/'DLP Program'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DLP Program\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L163t0QzoKka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videoFile = \"\"\n",
        "input(videoFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkzqewoGoSt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Breaks the video by frames for training set\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "x=1; count = 0\n",
        "while(cap.isOpened()):\n",
        "    # Current frame number\n",
        "    frameId = cap.get(1)\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    # Saves every 10th frame in the video, can be changed \n",
        "    if (frameId % 10 == 0): \n",
        "        filename ='temp/' + videoFile.split(' ')[0] +\"_frame%d.jpg\" % count;\n",
        "        count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPv4qoUwrdGp",
        "colab_type": "text"
      },
      "source": [
        "Part 2: Prepare the model we chose, this is what ours will look like for now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukS5FGyfrgL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uses the base model of pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Defining the architecture \n",
        "model = Sequential()\n",
        "model.add(Dense(1000, activation='relu', input_shape=(25088,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaK9MAirsJh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtJrNedAsZjq",
        "colab_type": "text"
      },
      "source": [
        "Part 3: Begin analyzing the frames!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNc9Ol53se2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating two lists to store predicted and actual tags\n",
        "predict = []\n",
        "\n",
        "images = glob(\"temp/*.jpg\")\n",
        "prediction_images = []\n",
        "for i in range(len(images)):\n",
        "    img = image.load_img(images[i], target_size=(224,224,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    prediction_images.append(img)\n",
        "prediction_images = np.array(prediction_images)\n",
        "prediction_images = base_model.predict(prediction_images)\n",
        "prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
        "prediction = model.predict(prediction_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LzIYSePt6I6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get timestamps\n",
        "clip = VideoFileClip(videoFile)\n",
        "timestamps = np.arange(0.0, clip.duration, clip.duration/(len(prediction)))\n",
        "\n",
        "# Get prediction values here\n",
        "prediction = prediction.transpose()\n",
        "pockets = prediction[2]\n",
        "erratic = prediction[1]\n",
        "drumming = prediction[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2nVZTAI9W-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot here!\n",
        "plt.title('Prediction results')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Guess (%)')\n",
        "\n",
        "plt.plot(timestamps, pockets)\n",
        "plt.plot(timestamps, erratic)\n",
        "plt.plot(timestamps, drumming)\n",
        "\n",
        "plt.savefig(videoFile.split('.')[0] + '_Predictions.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTdyAuMYGB_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates the json here!\n",
        "import json\n",
        "data1 = list(zip(timestamps, pockets))\n",
        "data2 = list(zip(timestamps, erratic))\n",
        "data3 = list(zip(timestamps, drumming))\n",
        "\n",
        "data1 = [list([float(i) for i in ele]) for ele in data1] \n",
        "data2 = [list([float(i) for i in ele]) for ele in data2] \n",
        "data3 = [list([float(i) for i in ele]) for ele in data3]\n",
        "\n",
        "print(data1)\n",
        "dicttemp = {'pockets':data1,'erratic':data2,'drumming':data3}\n",
        "with open(videoFile.split('.')[0] + '_data.json', 'w') as f:\n",
        "    json.dump(dicttemp, f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}