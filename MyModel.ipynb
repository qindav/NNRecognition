{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUSgz8AbSD84",
        "colab_type": "text"
      },
      "source": [
        "**This portion processes the videos into frames to prepare for learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQBqrVlRRdle",
        "colab_type": "text"
      },
      "source": [
        "This code uses methods provided in this tutorial [here](https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/) in order to process videos and setting up the neural net. Credits go to Pulkit Sharma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Jpw6vQJBWL",
        "colab_type": "code",
        "outputId": "3c8be7b4-b04d-4f7f-ff20-2d5de6a731ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Lots of headers, though some may be unused rn\n",
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2nSB5zZSC6o",
        "colab_type": "code",
        "outputId": "9f6cbc74-9721-4945-f301-c42f2db28572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPz3K1AmSa16",
        "colab_type": "code",
        "outputId": "1dcd6730-66ec-46a9-97f8-2028208c1bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/'My Drive'/Videos_DLP_v3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Videos_DLP_v3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GJVatLBSd_Y",
        "colab_type": "code",
        "outputId": "04114b36-fe35-4019-ce48-46eddfb99e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Prepares stuff for training\n",
        "# open the .txt file which have names of training videos\n",
        "f = open(\"Training.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating a dataframe using video names\n",
        "train = pd.DataFrame()\n",
        "train['video_name'] = videos\n",
        "train = train[:-1]\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drumming_1.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drumming_2.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Drumming_3.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Drumming_4.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Drumming_9.MP4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       video_name\n",
              "0  Drumming_1.MP4\n",
              "1  Drumming_2.MP4\n",
              "2  Drumming_3.MP4\n",
              "3  Drumming_4.MP4\n",
              "4  Drumming_9.MP4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJZcyc_P8Xsk",
        "colab_type": "code",
        "outputId": "118ee85c-2d6a-453a-c492-276783c1d6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Prepares stuff for testing\n",
        "# open the .txt file which have names of test videos\n",
        "f = open(\"Testing.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating a dataframe having video names\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drumming_5.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drumming_6.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Drumming_7.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Drumming_8.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Drumming_15.MP4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        video_name\n",
              "0   Drumming_5.MP4\n",
              "1   Drumming_6.MP4\n",
              "2   Drumming_7.MP4\n",
              "3   Drumming_8.MP4\n",
              "4  Drumming_15.MP4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UziZo_4VSzeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tag creation here\n",
        "# creating tags for training videos\n",
        "train_video_tag = []\n",
        "for i in range(train.shape[0]):\n",
        "    train_video_tag.append(train['video_name'][i].split('/')[0])\n",
        "    \n",
        "train['tag'] = train_video_tag\n",
        "\n",
        "# creating tags for test videos\n",
        "test_video_tag = []\n",
        "for i in range(test.shape[0]):\n",
        "    test_video_tag.append(test['video_name'][i].split('/')[0])\n",
        "    \n",
        "test['tag'] = test_video_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9SS08b_TtgQ",
        "colab_type": "code",
        "outputId": "09a2e148-9d6b-41f0-85fd-d98f0acd9c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Breaks the video by frames for training set\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = train['video_name'][i]\n",
        "    cap = cv2.VideoCapture(videoFile.split(' ')[0])   # capturing the video from the given path\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "    x=1\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "            # storing the frames in a new folder named train_1\n",
        "            filename ='training/' + videoFile.split(' ')[0] +\"_frame%d.jpg\" % count;count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 63/63 [02:35<00:00,  2.47s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQAUB2cQVK36",
        "colab_type": "code",
        "outputId": "dbb5d3dd-33e1-4d61-d91c-369fab7d0bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# getting the names of all the images for training set\n",
        "images = glob(\"training/*.jpg\")\n",
        "train_image = []\n",
        "train_class = []\n",
        "for i in tqdm(range(len(images))):\n",
        "    # creating the image name\n",
        "    train_image.append(images[i].split('/')[1])\n",
        "    # creating the class of image\n",
        "    vidclass = images[i].split('/')[1].split('_')[0]\n",
        "    train_class.append(vidclass.lower())\n",
        "    \n",
        "# storing the images and their class in a dataframe\n",
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class \n",
        "\n",
        "# converting the dataframename into csv file \n",
        "print(train_data['class'])\n",
        "train_data.to_csv('training/trains.csv',header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 447/447 [00:00<00:00, 226458.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0      drumming\n",
            "1      drumming\n",
            "2      drumming\n",
            "3      drumming\n",
            "4      drumming\n",
            "         ...   \n",
            "442    negative\n",
            "443    negative\n",
            "444    negative\n",
            "445    negative\n",
            "446    negative\n",
            "Name: class, Length: 447, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciBQQEE4cgfs",
        "colab_type": "code",
        "outputId": "baed382f-6a8a-48d8-874c-6f5dbae14c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Breaks the video by frames for testing set\n",
        "for i in tqdm(range(test.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = test['video_name'][i]\n",
        "    cap = cv2.VideoCapture(videoFile.split(' ')[0])   # capturing the video from the given path\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "    x=1\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        # Save frames every second\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "            filename ='testing/' + videoFile.split(' ')[0] +\"_frame%d.jpg\" % count;count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [01:14<00:00,  2.41s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQdYKlvWcrCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the names of all the images for testing set\n",
        "images = glob(\"testing/*.jpg\")\n",
        "test_image = []\n",
        "test_class = []\n",
        "for i in tqdm(range(len(images))):\n",
        "    # creating the image name\n",
        "    test_image.append(images[i].split('/')[1])\n",
        "    # creating the class of image\n",
        "    vidclass = images[i].split('/')[1].split('_')[0]\n",
        "    test_class.append(vidclass.lower())\n",
        "    \n",
        "# storing the images and their class in a dataframe\n",
        "test_data = pd.DataFrame()\n",
        "test_data['image'] = test_image\n",
        "test_data['class'] = test_class \n",
        "\n",
        "# converting the dataframename into csv file \n",
        "print(test_data['class'])\n",
        "test_data.to_csv('testing/testings.csv',header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp1BfqezdM2e",
        "colab_type": "text"
      },
      "source": [
        "**Get ready to train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CirotTL5ebeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDs8mt_7eihk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdWm8k_3epAk",
        "colab_type": "code",
        "outputId": "d4b6b4dc-1584-4719-d4da-ecd64b8002f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = pd.read_csv('training/trains.csv')\n",
        "train.head()\n",
        "# Setting up the frames here\n",
        "train_image = []\n",
        "\n",
        "# Processes the images here.\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img('training/'+train['image'][i], target_size=(224,224,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)\n",
        "    \n",
        "# convert to np array\n",
        "X = np.array(train_image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 447/447 [00:09<00:00, 49.59it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MkJiV6jezG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating validation set\n",
        "# separating the target\n",
        "y = train['class']\n",
        "\n",
        "# creating the training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)\n",
        "\n",
        "# creating dummies of target variable for train and validation set\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDZ8QnrBe2UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the base model of pre-trained VGG16 model\n",
        "# This is one form of CNN that can be used on each frame individually \n",
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-_gi80ZwpmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = base_model.predict(X_train) # extracting features for training frames\n",
        "X_test = base_model.predict(X_test) # extracting features for testing frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS-bRg5Hu3d4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcND3q0Zu8Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgfiXWN3e51j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshaping the training as well as validation frames\n",
        "X_train = X_train.reshape(357, 7*7*512)\n",
        "X_test = X_test.reshape(90, 7*7*512)\n",
        "\n",
        "# Normalizing the pixel values\n",
        "max = X_train.max()\n",
        "X_train = X_train/max\n",
        "X_test = X_test/max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7fRuIVFe7pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using the sequential architecture\n",
        "# Using three layers on the sequential model\n",
        "# TODO: Change the dropout between the layers\n",
        "# Sizes must also change\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(25088,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCo9ynkjfrC3",
        "colab_type": "text"
      },
      "source": [
        "Training Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTUaul-xfuNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIqK1q2ffv3k",
        "colab_type": "code",
        "outputId": "62160aaf-efd9-49dd-e498-c1f05caeb0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# training the model\n",
        "model.fit(X_train, y_train, epochs=40, validation_data=(X_test, y_test), callbacks=[mcp_save],  batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 357 samples, validate on 90 samples\n",
            "Epoch 1/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 1.3192 - accuracy: 0.3305 - val_loss: 1.0000 - val_accuracy: 0.5444\n",
            "Epoch 2/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 1.0410 - accuracy: 0.5126 - val_loss: 0.8267 - val_accuracy: 0.5778\n",
            "Epoch 3/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.8310 - accuracy: 0.5910 - val_loss: 0.6505 - val_accuracy: 0.6222\n",
            "Epoch 4/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.6611 - val_loss: 0.5918 - val_accuracy: 0.6556\n",
            "Epoch 5/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.6671 - accuracy: 0.6919 - val_loss: 0.5525 - val_accuracy: 0.7889\n",
            "Epoch 6/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.5599 - accuracy: 0.7283 - val_loss: 0.4660 - val_accuracy: 0.8778\n",
            "Epoch 7/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.4958 - accuracy: 0.7871 - val_loss: 0.3570 - val_accuracy: 0.9111\n",
            "Epoch 8/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.3865 - accuracy: 0.8375 - val_loss: 0.2366 - val_accuracy: 0.9444\n",
            "Epoch 9/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.2465 - accuracy: 0.9104 - val_loss: 0.1177 - val_accuracy: 0.9667\n",
            "Epoch 10/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.2229 - accuracy: 0.9188 - val_loss: 0.1355 - val_accuracy: 0.9778\n",
            "Epoch 11/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1419 - accuracy: 0.9608 - val_loss: 0.0806 - val_accuracy: 0.9778\n",
            "Epoch 12/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1093 - accuracy: 0.9636 - val_loss: 0.1555 - val_accuracy: 0.9667\n",
            "Epoch 13/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0855 - accuracy: 0.9776 - val_loss: 0.0508 - val_accuracy: 0.9889\n",
            "Epoch 14/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0652 - accuracy: 0.9804 - val_loss: 0.0720 - val_accuracy: 0.9889\n",
            "Epoch 15/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0548 - accuracy: 0.9804 - val_loss: 0.0599 - val_accuracy: 0.9889\n",
            "Epoch 16/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0294 - accuracy: 0.9888 - val_loss: 0.0264 - val_accuracy: 0.9889\n",
            "Epoch 17/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.0432 - val_accuracy: 0.9889\n",
            "Epoch 18/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0188 - accuracy: 0.9972 - val_loss: 0.0649 - val_accuracy: 0.9889\n",
            "Epoch 19/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0318 - accuracy: 0.9888 - val_loss: 0.0666 - val_accuracy: 0.9889\n",
            "Epoch 20/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.0820 - val_accuracy: 0.9889\n",
            "Epoch 21/40\n",
            "357/357 [==============================] - 2s 7ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9889\n",
            "Epoch 22/40\n",
            "357/357 [==============================] - 3s 8ms/step - loss: 0.0099 - accuracy: 0.9944 - val_loss: 0.0425 - val_accuracy: 0.9889\n",
            "Epoch 23/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0501 - val_accuracy: 0.9889\n",
            "Epoch 24/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.0875 - val_accuracy: 0.9889\n",
            "Epoch 25/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0231 - accuracy: 0.9972 - val_loss: 0.0917 - val_accuracy: 0.9889\n",
            "Epoch 26/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.0509 - val_accuracy: 0.9889\n",
            "Epoch 27/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0405 - val_accuracy: 0.9889\n",
            "Epoch 28/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0161 - accuracy: 0.9972 - val_loss: 0.0403 - val_accuracy: 0.9889\n",
            "Epoch 29/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.0724 - val_accuracy: 0.9889\n",
            "Epoch 30/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.0644 - val_accuracy: 0.9889\n",
            "Epoch 31/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.0724 - val_accuracy: 0.9889\n",
            "Epoch 32/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9889\n",
            "Epoch 33/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9889\n",
            "Epoch 34/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9889\n",
            "Epoch 35/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9889\n",
            "Epoch 36/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9889\n",
            "Epoch 37/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9889\n",
            "Epoch 38/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 9.2599e-04 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9889\n",
            "Epoch 39/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9889\n",
            "Epoch 40/40\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 5.5667e-04 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0b65cf6eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTvaQ1NHte4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKMfMxomgccO",
        "colab_type": "text"
      },
      "source": [
        "**Time to test everything here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvLBeRHgghc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from scipy import stats as s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rrEks9QhiXw",
        "colab_type": "code",
        "outputId": "febf2aa7-6461-49cc-b9a0-bf9986e86ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# getting the test list\n",
        "f = open(\"Testing.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating the dataframe\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test_videos = test['video_name']\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drumming_5.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drumming_6.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Drumming_7.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Drumming_8.MP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Drumming_15.MP4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        video_name\n",
              "0   Drumming_5.MP4\n",
              "1   Drumming_6.MP4\n",
              "2   Drumming_7.MP4\n",
              "3   Drumming_8.MP4\n",
              "4  Drumming_15.MP4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPbvlH9qhozb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the tags\n",
        "train = pd.read_csv('training/trains.csv')\n",
        "y = train['class']\n",
        "y = pd.get_dummies(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV2nACCU6X4P",
        "colab_type": "code",
        "outputId": "27123845-b892-46fd-9cbd-34358919707d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# creating two lists to store predicted and actual tags\n",
        "predict = []\n",
        "actual = []\n",
        "\n",
        "# for loop to extract frames from each test video\n",
        "for i in tqdm(range(test_videos.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = test_videos[i]\n",
        "    cap = cv2.VideoCapture(videoFile.split(' ')[0])   # capturing the video from the given path\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "    # removing all other files from the temp folder\n",
        "    # !rm -rf temp\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "            # storing the frames of this particular video in temp folder\n",
        "            filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()\n",
        "    \n",
        "    # reading all the frames from temp folder\n",
        "    images = glob(\"temp/*.jpg\")\n",
        "    prediction_images = []\n",
        "    for i in range(len(images)):\n",
        "        img = image.load_img(images[i], target_size=(224,224,3))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img/255\n",
        "        prediction_images.append(img)\n",
        "    prediction_images = np.array(prediction_images)\n",
        "    prediction_images = base_model.predict(prediction_images)\n",
        "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
        "    prediction = model.predict_classes(prediction_images)\n",
        "    # appending the mode of predictions in predict list to assign the tag to the video\n",
        "    predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
        "\n",
        "    # appending the actual tag of the video\n",
        "    vidclass = (videoFile.split('_')[0])\n",
        "    actual.append(vidclass.lower())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [02:38<00:00,  5.11s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27pdRO-t0HWJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5BJdDyyioyu",
        "colab_type": "code",
        "outputId": "c99c6fba-a80d-4d0b-a5c5-8681edc6409a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 0: drumming\n",
        "# 1: erratic\n",
        "# 2: pockets\n",
        "# checking the accuracy of the predicted tags\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(predict, actual)*100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90.32258064516128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTCn9-l6RXKV",
        "colab_type": "text"
      },
      "source": [
        "The end!\n"
      ]
    }
  ]
}